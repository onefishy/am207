# Week 5

### Lecture
- Lecture #8: Metropolis-Hastings and Gibbs
  - [Lecture Video](https://youtu.be/y1WNKlA1ZhU)
  - [Lecture Notes](https://github.com/onefishy/am207/blob/master/Lectures/lecture_8_notes.ipynb)
  - [Lecture Summary](https://github.com/onefishy/am207/blob/master/Lectures/lecture_8_summary.ipynb)
- Lecture #9: Latent Variable Models and MLE
  - [Lecture Video](https://youtu.be/KWv5k1QaXIk)
  - [Lecture Notes](https://github.com/onefishy/am207/blob/master/Lectures/lecture_9_notes.ipynb)

### Activities
- [In-Class Exercise #8: Metropolis-Hastings and Gibbs Sampling](https://deepnote.com/workspace/weiwei-pan-2902decb-902f-40cc-9fa6-af2e3f31f15b/project/AM207Fall202108-MH-and-Gibbs-ffeba275-6f2a-417c-be99-0eb0d0b27bfb)
- [In-Class Exercise #8: Solutions](https://deepnote.com/workspace/weiwei-pan-2902decb-902f-40cc-9fa6-af2e3f31f15b/project/Solutions-AM207Fall202108-MH-and-Gibbs-e33b8b42-caf0-494e-b2d1-a48a7ce8862c/%2FIn-Class%20Exercises%2F08_MH_and_Gibbs.ipynb)
- [In-Class Exercise #9: Expectation Maximization](https://deepnote.com/workspace/weiwei-pan-2902decb-902f-40cc-9fa6-af2e3f31f15b/project/AM207Fall202109-expectation-maximization-97a1d7fd-43fc-4570-810f-b2b90ef480be)
- [Homework #4](https://github.com/onefishy/am207/blob/master/HW/AM207_HW4.ipynb)
- [Homework #4 Solutions](https://github.com/onefishy/am207/blob/master/HW/AM207_HW4_Solutions.ipynb)

### Reading

**Applications and Broader Impact:**

1.  [Item Response Theory for assessing students and questions (pt. 1)](https://medium.com/@lucabenedetto/advantages-in-using-item-response-theory-for-assessing-students-and-more-4a9665258863)
2.  [Simultaneous Discovery, Estimation and Prediction Analysis of Complex Traits Using a Bayesian Mixture Model](https://journals.plos.org/plosgenetics/article?id=10.1371/journal.pgen.1004969)
3.  [Parkinson’s Disease Subtypes in the Oxford Parkinson Disease Centre (OPDC) Discovery Cohort](https://content.iospress.com/articles/journal-of-parkinsons-disease/jpd140523)
4.  [One Size Doesn’t Fit All: Using Factor Analysis to Gather Validity Evidence When Using Surveys in Your Research](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6757227/)

**MCMC Diagnostics:**

1.  (Introductory) [Markov Chain Monte Carlo (MCMC) Diagnostics](https://www.statlect.com/fundamentals-of-statistics/Markov-Chain-Monte-Carlo-diagnostics)
2.  (In-Depth) [Convergence diagnostics for Markov chain Monte Carlo](https://arxiv.org/pdf/1909.11827.pdf)
3.  (Opinion) [On the Bogosity of MCMC Diagnostics](http://users.stat.umn.edu/~geyer/mcmc/diag.html)

**More on Thinning:**

1.  (Thinning is bad!) [On Thinning of Chains in MCMC](https://besjournals.onlinelibrary.wiley.com/doi/epdf/10.1111/j.2041-210X.2011.00131.x)
2.  (Thinning can be good!) [Statistically efficient thinning of a Markov chain sampler](https://arxiv.org/pdf/1510.07727.pdf)

**More on Chain Length:**

1.  (The longer the better? Not always) [Unbiased Markov chain Monte Carlo with couplings](https://arxiv.org/pdf/1708.03625.pdf)

**Latent Variable Models:**

1.  (Introductory) [Build, Compute, Critique, Repeat: Data Analysis with Latent Variable Models](http://www.cs.columbia.edu/~blei/papers/Blei2014b.pdf)
2.  (Introductory) [Theory and Use of the EM Algorithm](http://mayagupta.org/publications/EMbookGuptaChen2010.pdf)
