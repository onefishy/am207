# Course Project Description

<p>The aim of the project is to acclimate you to the process of conducting research in statistical modeling or machine learning: 1) tackle an intimidatingly general problem 2) narrow the scope to a specific set of parameters to study 3) replicate existing literature studying these parameters 4) innovate on top of existing work incrementally, and 5) consider the wider socio-technological impact of your work.</p>
<p>Students who make meaningful novel or insightful contributions in their course projects have the opportunity to develop their project into a workshop or conference publication during the&nbsp;Spring 2022 semester. Examples of publications from AM207 Fall 2021:</p>
<ul>
    <li><a class="inline_disabled" href="https://arxiv.org/abs/2106.13314" target="_blank" rel="noopener">Promises and Pitfalls of Black-Box Concept Learning Models</a></li>
    <li><a class="inline_disabled" href="http://www.gatsby.ucl.ac.uk/~balaji/udl2021/accepted-papers/UDL2021-paper-030.pdf" target="_blank" rel="noopener">Safety &amp; Exploration: A Comparative Study of Uses of Uncertainty in Reinforcement Learning</a></li>
</ul>
<p><strong>Due:</strong></p>
<ol>
    <li style="list-style-type: none;">
        <ol>
            <li><span style="color: #000000;"><span style="color: #ff0000;">(October 2nd)</span> Project Checkpoint #1: Team Formation</span>
                <ul>
                    <li><span style="color: #000000;">Submit the names of your team members</span></li>
                </ul>
            </li>
            <li><span style="color: #000000;"><span style="color: #ff0000;">(October 23rd)</span> Project Checkpoint #2: Paper Selection</span>
                <ul>
                    <li><span style="color: #000000;">Meet with the instructor to discuss paper choice prior to this date</span></li>
                    <li><span style="color: #000000;">Submit the name of your paper</span></li>
                </ul>
            </li>
            <li><span style="color: #000000;"><span style="color: #ff0000;">(November 6th)</span> Project Checkpoint #3: Paper Overview</span>
                <ul>
                    <li><span style="color: #000000;">Meet with your assigned TF prior to this date to discuss your paper</span></li>
                    <li><span style="color: #000000;">Submit a summary of the high-level ideas of your paper&nbsp;</span></li>
                </ul>
            </li>
            <li><span style="color: #000000;"><span style="color: #ff0000;">(November 20th)</span> Project Checkpoint #4: Pedagogical Examples</span>
                <ul>
                    <li><span style="color: #000000;">Meet with the instructor prior to this date to discuss plans for implementation and pedagogical examples</span></li>
                    <li><span style="color: #000000;">Show implementation/experimentation in progress</span></li>
                </ul>
            </li>
            <li><span style="color: #000000;"><span style="color: #ff0000;">(December 17th) Final Deliverable Due</span></span></li>
        </ol>
    </li>
</ol>
<p><strong><span style="color: #000000;">Grading:&nbsp;</span></strong><span style="color: #000000;">Your grade is based on:</span></p>
<ol>
    <li><span style="color: #000000;">&nbsp;How well your deliverable satisfies the project specifications (described below)</span></li>
    <li><span style="color: #000000;">Your progress leading up to the final deliverable. There will be a series of check points with your project TF and instructor through out the semester. Your final grade will account for how much progress you've made by each check point.</span></li>
</ol>
<p><strong>Instructions: </strong></p>
<ul>
    <li><strong>Team:</strong> Form a team of 2-4 people</li>
    <li><strong>Topic:</strong> Choose a paper from the approved list of papers (we are limiting 2 teams per paper, on a first-come-first-serve basis). You may propose a paper, but it must be approved by your instructor.</li>
    <li><strong>Mentoring:</strong>&nbsp;You will have a designated TF for your project and you are welcomed to schedule meetings between your team and the instructor.</li>
    <li><strong>Project deliverable:&nbsp;</strong>A well-formatted Jupyter notebook (optimized for readability) containing:
        <ul>
            <li><strong>Clear exposition of :&nbsp;</strong>
                <ul>
                    <li><em><strong>Problem statement</strong></em> - what is the problem the paper aims to solve?</li>
                    <li><em><strong>Context/scope</strong></em> - why is this problem important or interesting?</li>
                    <li><em><strong>Existing work</strong></em> - what has been done in literature?</li>
                    <li><em><strong>Contribution</strong></em> - what is gap in literature that the paper is trying to fill? What is the unique contribution</li>
                    <li><em><strong>Technical content (high level)</strong> </em>- what are the high level ideas behind their technical contribution</li>
                    <li><em><strong>Technical content (details)</strong> </em>- <strong><em>highlight (not copy and paste entire sections)</em>&nbsp;</strong>the relevant details that are important to focus on (e.g. if there's a model, define it; if there is a theorem, state it and explain why it's important, etc).</li>
                    <li><em><strong>Experiments</strong> </em>- which types of experiments were performed? What claims were these experiments trying to prove? Did the results prove the claims?</li>
                    <li><em><strong>Evaluation (your opinion)</strong></em> - do you think the work is technically sound? Do you think the proposed model/inference method is practical to use on real data and tasks? Do you think the experimental section was strong (there are sufficient evidence to support the claims and eliminate confounding factors)?</li>
                    <li><em><strong>Future work (for those interested in continuing research in a related field)</strong></em> - do you think you can suggest a concrete change or modification that would improve the existing solution(s) to the problem of interest? Try to implement some of these changes/modifications.</li>
                    <li><em><strong>Broader Impact</strong></em> - how does this work potentially impact (both positively and negatively) the broader machine learning community and society at large when this technology is deployed? In the applications of this technology, who are the potentially human stakeholders? What are the potential risks to the interest of these stakeholders in the failure modes of this technology? Is there potential to exploit this technology for malicious purposes?</li>
                </ul>
            </li>
        </ul>
    </li>
</ul>
<p style="padding-left: 40px;">Your exposition should focus on summarization and highlighting (aiming for an audience of peers who have taken AM207). There is no point rewording the paper itself. Reorganize and explain the ideas in a way that makes sense to you, that features the most salient/important aspects of the paper, that demonstrates understanding and synthesis.</p>
<ul>
    <li style="list-style-type: none;">
        <ul>
            <li><strong>Code:</strong>
                <ul>
                    <li>At least one clear working pedagogical example demonstrating the problem the paper is claiming to solve.&nbsp;</li>
                    <li>At lease a bare bones implementation of the model/algorithm/solution (in some cases, you may be able to make assumptions &nbsp;to simplify the model/algorithm/solution with the approval of your instructor)</li>
                    <li>Demonstration on at least one instance that your implementation solves the problem.</li>
                    <li>Demonstration on at least one instance the failure mode of the model/algorithm/solution, with an explanation for why failure occurred (is the dataset too large? Did you choose a bad hyper parameter?). The point of this is to point out edge cases to the user.</li>
                </ul>
            </li>
        </ul>
    </li>
</ul>
<p style="padding-left: 40px;">You are welcome to study any code that is provided with the paper, you are however not allowed to copy code. Your implementation must be your own. If a public repo is available for your paper, you are encouraged to first try reproducing some results using the authors code -- this will give you an idea of how their algorithm/model works.</p>
<p><strong>Examples of Project from Fall 2019:</strong></p>
<p><a href="https://github.com/onefishy/am207_fall19_projects">Github repo of Fall 2019 AM207 projects</a></p>
<p><strong>List of Pre-Approved Papers:&nbsp;</strong></p>
<p><em>Out of Distribution Detection, Dataset Shifts</em></p>
<ol>
    <li><a class="inline_disabled" href="https://auai.org/uai2021/pdf/uai2021.672.preliminary.pdf" target="_blank" rel="noopener">Know Your Limits: Uncertainty Estimation with ReLU Classifiers Fails at Reliable OOD Detection</a></li>
    <li><a class="inline_disabled" href="https://auai.org/uai2021/pdf/uai2021.328.preliminary.pdf" target="_blank" rel="noopener">Identifying Untrustworthy Predictions in Neural Networks by Geometric Gradient Analysis</a></li>
    <li><a class="inline_disabled" href="https://arxiv.org/pdf/2106.10151.pdf" target="_blank" rel="noopener">The Dimpled Manifold Model of Adversarial Examples in Machine Learning</a></li>
    <li><a class="inline_disabled" href="https://arxiv.org/abs/1905.02175" target="_blank" rel="noopener">Adversarial Examples are not Bugs, they are Features</a>;&nbsp;<a class="inline_disabled" href="https://distill.pub/2019/advex-bugs-discussion/" target="_blank" rel="noopener">A Discussion of Adversarial Examples Are Not Bugs, They Are Features</a>&nbsp;</li>
    <li><a class="inline_disabled" href="https://arxiv.org/abs/2012.07421" target="_blank" rel="noopener">Wilds: A Benchmark of in-the-Wild Distribution Shifts</a></li>
    <li><a class="inline_disabled" href="https://arxiv.org/abs/2007.08176" target="_blank" rel="noopener">CSI: Novelty Detection via Contrastive Learning on Distributionally Shifted Instances</a></li>
    <li><a class="inline_disabled" href="https://arxiv.org/pdf/2106.04260.pdf" target="_blank" rel="noopener">Provably Robust Detection of Out-of-distribution Data (almost) for free</a>&nbsp;</li>
</ol>
<p><em>Interpretations, Explanations, Fairness of Models</em></p>
<ol>
    <li><a class="inline_disabled" href="https://auai.org/uai2021/pdf/uai2021.531.preliminary.pdf" target="_blank" rel="noopener">Local Explanations via Necessity and Sufficiency: Unifying Theory and Practice</a>&nbsp;</li>
    <li><a class="inline_disabled" href="https://arxiv.org/abs/2012.03058" target="_blank" rel="noopener">BayLIME: Bayesian Local Interpretable Model-Agnostic Explanations BayLIME: Bayesian Local Interpretable Model-Agnostic Explanations</a></li>
    <li><a class="inline_disabled" href="https://arxiv.org/pdf/2108.10346.pdf" target="_blank" rel="noopener">Explaining Bayesian Neural Networks</a></li>
    <li><a class="inline_disabled" href="https://auai.org/uai2021/pdf/uai2021.289.preliminary.pdf" target="_blank" rel="noopener">Measuring Data Leakage in Machine-Learning Models with Fisher Information</a></li>
    <li><a class="inline_disabled" href="http://proceedings.mlr.press/v130/jethani21a/jethani21a.pdf" target="_blank" rel="noopener">Have We Learned to Explain?: How Interpretability Methods Can Learn to Encode Predictions in their Interpretations</a></li>
    <li><a class="inline_disabled" href="https://arxiv.org/abs/1910.00199" target="_blank" rel="noopener">Saliency is a Possible Red Herring When Diagnosing Poor Generalization</a></li>
    <li><a class="inline_disabled" href="https://arxiv.org/abs/2010.14134" target="_blank" rel="noopener">Selective Classification Can Magnify Disparities Across Groups</a></li>
    <li><a class="inline_disabled" href="https://arxiv.org/abs/1909.00066" target="_blank" rel="noopener">Counterfactual risk assessments, evaluation, and fairness</a></li>
    <li><a class="inline_disabled" href="https://arxiv.org/pdf/2106.05945.pdf" target="_blank" rel="noopener">Does knowledge distillation really work?</a></li>
    <li><a class="inline_disabled" href="http://&nbsp;https://arxiv.org/pdf/2106.12563.pdf" target="_blank" rel="noopener">Feature Attributions and Counterfactual Explanations Can Be Manipulated</a></li>
    <li><a class="inline_disabled" href="https://arxiv.org/pdf/1806.02711.pdf" target="_blank" rel="noopener">POTs: Protective Optimization Technologies</a>&nbsp;</li>
    <li><a class="inline_disabled" href="https://www.cse.cuhk.edu.hk/~qdou/papers/IMLH2021_files/28_CameraReady_reliable-post-hoc-expl-main.pdf" target="_blank" rel="noopener">Reliable Post hoc Explanations: Modeling Uncertainty in Explainability</a></li>
    <li><a class="inline_disabled" href="https://dl.acm.org/doi/10.1145/3442188.3445883" target="_blank" rel="noopener">Removing Spurious Features can Hurt Accuracy and Affect Groups Disproportionately</a></li>
</ol>
<p><em>Impacts and Applications of ML</em></p>
<ol>
    <li><a class="inline_disabled" href="https://arxiv.org/abs/2006.06462" target="_blank" rel="noopener">Learning advanced mathematical computations from examples</a></li>
    <li><a class="inline_disabled" href="https://arxiv.org/abs/2102.00128" target="_blank" rel="noopener">The effect of differential victim crime reporting on predictive policing systems</a>; <a class="inline_disabled" href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3377921" target="_blank" rel="noopener">Beyond Bias: Re-Imagining the Terms of &lsquo;Ethical AI&rsquo; in Criminal Law</a>&nbsp;</li>
    <li><a class="inline_disabled" href="https://arxiv.org/abs/2101.12267" target="_blank" rel="noopener">A Bayesian Model of Cash Bail Decisions</a></li>
    <li><a class="inline_disabled" href="https://static1.squarespace.com/static/59d5ac1780bd5ef9c396eda6/t/5f22cb918495c37ad77ddfc8/1596115860385/67_CameraReadySubmission_Phenotyping_with_Prior_Knowledge.pdf" target="_blank" rel="noopener">Phenotyping with Prior Knowledge using Patient Similarity</a></li>
    <li><a class="inline_disabled" href="https://static1.squarespace.com/static/59d5ac1780bd5ef9c396eda6/t/5f22cc6001967113c01df084/1596116068204/130_CameraReadySubmission_camera_ready_paper.pdf" target="_blank" rel="noopener">Hidden Risks of Machine Learning Applied to Healthcare: Unintended Feedback Loops Between Models and Future Data Causing Model Degradation</a></li>
    <li><a class="inline_disabled" href="https://static1.squarespace.com/static/59d5ac1780bd5ef9c396eda6/t/60fb3ae8379556598ce0aab4/1627077353303/mlhc_risk_score_learn_camera.pdf" target="_blank" rel="noopener">Risk score learning for COVID-19 contact tracing apps</a></li>
    <li><a class="inline_disabled" href="https://static1.squarespace.com/static/59d5ac1780bd5ef9c396eda6/t/60fb398fa29a3362540d341d/1627077008496/MLHC_Paper+%284%29.pdf" target="_blank" rel="noopener">CheXbreak: Misclassification Identification for Deep Learning Models Interpreting Chest X-rays</a></li>
</ol>
<p><em>Deep Bayesian and Ensemble Models</em></p>
<ol>
    <li><a class="inline_disabled" href="https://auai.org/uai2021/pdf/uai2021.682.preliminary.pdf" target="_blank" rel="noopener">Variational Refinement for Importance Sampling Using the Forward Kullback-Leibler Divergence</a></li>
    <li><a class="inline_disabled" href="https://auai.org/uai2021/pdf/uai2021.683.preliminary.pdf" target="_blank" rel="noopener">Diagnostics for Conditional Density Models and Bayesian Inference Algorithms</a></li>
    <li><a class="inline_disabled" href="https://auai.org/uai2021/pdf/uai2021.536.preliminary.pdf" target="_blank" rel="noopener">Post-hoc loss-calibration for Bayesian neural networks</a>&nbsp;</li>
    <li><a class="inline_disabled" href="https://auai.org/uai2021/pdf/uai2021.274.preliminary.pdf" target="_blank" rel="noopener">Scaling Hamiltonian Monte Carlo Inference for Bayesian Neural Networks with Symmetric Splitting</a>&nbsp;</li>
    <li><a class="inline_disabled" href="https://auai.org/uai2021/pdf/uai2021.145.preliminary.pdf" target="_blank" rel="noopener">Learnable Uncertainty under Laplace Approximations</a>&nbsp;</li>
    <li><a class="inline_disabled" href="https://openreview.net/pdf?id=KtY5qphxnCv" target="_blank" rel="noopener">Rethinking Function-Space Variational Inference in Bayesian Neural Networks</a></li>
    <li><a class="inline_disabled" href="http://proceedings.mlr.press/v130/maddox21a/maddox21a.pdf" target="_blank" rel="noopener">Fast Adaptation with Linearized Neural Networks</a>&nbsp;</li>
    <li><a class="inline_disabled" href="https://arxiv.org/abs/2011.03178" target="_blank" rel="noopener">Beyond Marginal Uncertainty: How Accurately can Bayesian Regression Models Estimate Posterior Predictive Correlations?</a></li>
    <li><a class="inline_disabled" href="https://arxiv.org/abs/2010.14689" target="_blank" rel="noopener">Bayesian Deep Learning via Subnetwork Inference</a></li>
    <li><a class="inline_disabled" href="https://arxiv.org/abs/2104.14421" target="_blank" rel="noopener">What Are Bayesian Neural Network Posteriors Really Like?</a></li>
    <li><a class="inline_disabled" href="https://arxiv.org/abs/2102.13042" target="_blank" rel="noopener">Loss Surface Simplexes for Mode Connecting Volumes and Fast Ensembling</a></li>
    <li><a class="inline_disabled" href="https://arxiv.org/abs/2010.04230" target="_blank" rel="noopener">No MCMC for Me: Amortized Sampling for Fast and Stable Training of Energy-Based Models</a></li>
    <li><a class="inline_disabled" href="http://www.gatsby.ucl.ac.uk/~balaji/udl2021/accepted-papers/UDL2021-paper-003.pdf" target="_blank" rel="noopener">Repulsive Deep Ensembles are Bayesian Repulsive Deep Ensembles are Bayesian</a></li>
    <li><a class="inline_disabled" href="https://arxiv.org/abs/2102.10472" target="_blank" rel="noopener">Learning Neural Network Subspaces</a></li>
    <li><a class="inline_disabled" href="http://www.gatsby.ucl.ac.uk/~balaji/udl2021/accepted-papers/UDL2021-paper-035.pdf" target="_blank" rel="noopener">Deep Ensemble Uncertainty Fails as Network Width Increases: Why, and How to Fix It</a></li>
</ol>
