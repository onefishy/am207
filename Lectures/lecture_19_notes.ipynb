{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture #19: Variational Inference in Context\n",
    "## AM 207: Advanced Scientific Computing\n",
    "### Stochastic Methods for Data Analysis, Inference and Optimization\n",
    "### Fall, 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"fig/logos.jpg\" style=\"height:150px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "### Import basic libraries\n",
    "import numpy\n",
    "import autograd.numpy as np\n",
    "import autograd.numpy.random as npr\n",
    "import autograd.scipy.stats.multivariate_normal as mvn\n",
    "import autograd.scipy.stats.norm as norm\n",
    "from autograd import grad\n",
    "from autograd.misc.optimizers import adam\n",
    "import numpy\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import math\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib import rc\n",
    "from IPython.display import HTML\n",
    "from IPython.display import YouTubeVideo\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Outline\n",
    "1. How to Evaluate Approximate Inference\n",
    "2. How to Improve Approximate Inference\n",
    "3. Why do I care?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# How to Evaluate Approximate Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How Good is Your Variational Approximation of the True Posterior?\n",
    "\n",
    "**Question:** Why is it hard to check that the variational posterior is a good approximation of the true posterior?\n",
    "\n",
    "You can't simply visualize the true posterior, since it's 1) high dimensional, 2) intractable to sample form.\n",
    "\n",
    "**Question:** What if we computed the KL-divergence between the true posterior and the varaitional approximation?\n",
    "\n",
    "[\"Practical Posterior Error Bounds from Variational Objectives\"](https://arxiv.org/abs/1910.04102): Unfortunately, even when the KL-divergence between $q$ and $p$ is effectively zero, the difference between the means and variances of $q$ and $p$ can be **arbitrarily large**. That is, a small KL-divergence doesn't capture our intuition about what it means for two distributions to be similar.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Alternative Posterior Evaluation Metrics\n",
    "\n",
    "In [\"Yes, But Did It Work: Evaluating Variational Inference\"](https://arxiv.org/abs/1802.02538), the authors proposes two alternative posterior evaluation metrics:\n",
    "\n",
    "**1. The Pareto Smoothed Importance Sampling Diagnostic**: If the variational approximation $q$ is very different than $p$, then the importance sampling MC estimate of $\\mathbb{E}_{p(\\theta|\\text{Data})}\\left[ f(\\theta) \\right]$,\n",
    "$$\n",
    "\\mathbb{E}_{p(\\theta|\\text{Data})}\\left[ f(\\theta) \\right] \\approx \\frac{1}{S}\\sum_{s=1}^S \\frac{p(\\theta|\\text{Data})}{q(\\theta)} f(\\theta_s),\\; \\theta_s \\sim q(\\theta)\n",
    "$$\n",
    "will have very high variance, due to the fact that the importance weights $\\frac{p(\\theta|\\text{Data})}{q(\\theta)}$ will be very heterogeneous. Thus, methods of smoothing the weights, like ***Pareto Smoothed Importance Sampling (PSIS)*** will have poor performance. The efficacy of PSIS can be used as a diagnostic tool for testing if $q$ is similar to $p$.\n",
    "\n",
    "**2. The Variational Simulation-Based Calibration (VSBC) Diagnostic**: Given a Bayesian model $p(y, \\theta) = p(y|\\theta) p(\\theta)$, if your variational inference proceedure is good at approximating the posterior $p(\\theta|y)$ then it should do well for most sets of data that is generated from the model $p(y, \\theta)$.\n",
    "\n",
    "We generate $M$ sets of synthetic data from $p(y, \\theta)$. For each set of the data we approximate the posterior $q_m(\\theta)$. We then perform a calibration test on each variational approximation. This will reveal if your variational inference procedure is biased - produces approximation that are consistently flawed in some specific way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# How to Improve Approximate Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Your Variational Approximation Sucks, Can You Fix It?\n",
    "\n",
    "The current research on improving variational inference can be categorize by which **design choice** each work tries to improve:\n",
    "\n",
    "**1. Choice of Divergence:** In Lab #5, you explored the draw-backs of fitting an approximate posterior $q$ to the true posterior $p$ using KL-divergence. There are a huge number of works that explore performing variational inference using other types of divergences, for example: <br>\n",
    "$\\quad$ **a.** [\"Black-box $\\alpha$-divergence Minimization\"](https://arxiv.org/abs/1511.03243)<br>\n",
    "$\\quad$ **b.** [\"Stein Variational Gradient Descent\"](https://arxiv.org/abs/1608.04471)\n",
    "\n",
    "**2. Choice of Variational Family:** In Homework #0, you've seen that even for a simple Bayesian linear regression model, the model parameters were corrlated in the posterior. In Lab #7, you've seen that minimizing the KL-divergence to fit an isotropic Gaussian means that you can only capture one mode in the posterior. There are a huge number of works that explore using different types of variational families:<br>\n",
    "$\\quad$ **a.** [\"Variational Inference with Normalizing Flows\"](https://arxiv.org/abs/1505.05770)<br>\n",
    "$\\quad$ **b.** [\"The Variational Gaussian Process\"](https://arxiv.org/abs/1511.06499)<br>\n",
    "\n",
    "**3. Choice of Optimization Procedure:** Even if your divergence measure and variational family are well-chosen, the optimization objective can still be non-convex! This means that your optimization procedure might return a $q$ that is a only local-optimum. There are a large number of works that address how to jump out of local optima using SGD and some works that specifically address the optimization challenges of variational inference:<br>\n",
    "$\\quad$ **a.** [\"Proximity Variational Inference\"](https://arxiv.org/abs/1705.08931)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Are There Any Good Properties of Variational Approximations that We Are Sure About?\n",
    "\n",
    "In [\"Frequentist Consistency of Variational Bayes\"](https://arxiv.org/abs/1705.03439), the authors prove that under **certain assumptions** on $p(\\theta)$ and $p(y|\\theta)$:\n",
    "1.  as the number of observation increases, the variational approximation converges (in Total Variation distance) to the $q$ that minimizes the KL-divergence to a normal distribution centered at the ground truth parameters $\\theta_{\\text{true}}$ that generated the data.<br><br>\n",
    "2. the mean of the variational approximation is consistent and asymptoptically normal.\n",
    "\n",
    "Unfortunately, the assumptions required by the theorems **do not hold for neural network likelihood models**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Why is Inference for Neural Networks Hard?\n",
    "\n",
    "Research on the likelihoods (and hence posteriors) of neural networks are beginning to give us ways of visualizing these high-dimensional functions using low-dimensional (3D) projections. [Loss Landsacapes](https://losslandscape.com) represents some of the latest efforts at visualization:\n",
    "\n",
    "<img src=\"fig/loss.jpg\" style=\"height:400px;\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## It's Weirder Than You Can Imagine\n",
    "\n",
    "In [\"Loss Landscape Sightseeing with Multi-Point Optimization\"](https://arxiv.org/pdf/1910.03867.pdf), the authors show that neural network likelihoods (and thus posteriors) are so complicated that you can find a 2-D projection that can create any pattern you want:\n",
    "\n",
    "<img src=\"fig/loss2.jpg\" style=\"height:250px;\" align=\"center\"/>\n",
    "\n",
    "**The lesson**: take every low-dimensional visualization with a grain of salt (i.e. it far from accurately represents the entire landscape)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# But why do I care?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Evaluation of Variational Approximation for Real Down-stream Tasks\n",
    "\n",
    "In practice, you may only care about the quality of your posterior approximation in so far as it affects model performance on your down-stream task. So what do we want from our machine learning or statistical models, especially when they are used in safety, or fairness critical applications (e.g. personalized medicine, health-care resource allocation, criminal justic systems)?\n",
    "\n",
    "Most of us in the community agree that we want models that *1)* makes accurate predictions *2)* gives realistic estimates of its prective uncertainty. So that the model can be held-accountable by humans in the system. There are a number of subcomunities in ML that focus on studying the social impact of machine learning models as well as how to design models whose negative impact can be mitigated.\n",
    "\n",
    "**a.** [\"Concrete Problems in AI Safety\"](https://arxiv.org/pdf/1606.06565.pdf)<br>\n",
    "**b.** [\"Predict Responsibly: Improving Fairness and Accuracy by Learning to Defer\"](https://papers.nips.cc/paper/7853-predict-responsibly-improving-fairness-and-accuracy-by-learning-to-defer.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Predictiveness of the Variational Approximate Posterior\n",
    "\n",
    "We can check the predictiveness of our varational approximation of the posterior by sampling models from the posterior and then making predictions using these models by sampling from the likelihood. We then check that these predictions align well with observed data by:\n",
    "\n",
    "1. **Visualization:** visualizing the posterior predictive against the observed data. *This is generally impossible for high dimensional data.*<br><br>\n",
    "\n",
    "2. **Log Marginal Data Likelihood:** we compute the expected value of the log likelihood of the test data under our approximate posterior. *Log likelihood is only useful for comparing two different models, given a single model it is hard to say if a log likelihood value is \"good enough\".*<br><br>\n",
    "\n",
    "3. **Expected Mean Square Error and Accuracy:** we compute the expected MSE (for regression) or accuracy (for classification) on test data under our approximate posterior. *While these metric frames model quality in concrete task related terms, they are each misleading when the data contains outliers or imbalanced classes.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Quality of Variational Approximate Posterior Predictive Uncertainty\n",
    "\n",
    "We've argued in this course that good predictive uncertainty must involve an accurate assessment of both ***epistemic*** and ***aleatoric*** uncertainty. Since each type of uncertainty requires a different risk-management action in the down-stream task.\n",
    "\n",
    "<img src=\"fig/posterior_pred.jpg\" style=\"height:210px;\" align=\"center\"/>\n",
    "\n",
    "Unfortunately, there isn't a single good statistical metric for assessing the quality of the uncertainty of a model. \"Good\" epstemic uncertainty is especially hard to quantify. Rather than looking for statistical tests of uncertainty, some in the ML community advocate for assessing model uncertainty with respect to a set of benchmark down-stream tasks: [Bayesian Deep Learning Benchmarks](https://github.com/OATML/bdl-benchmarks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Does a Poor Posterior Approximation Imply a Poor Posterior Predictive?\n",
    "You've seen in HW#7 that even with an HMC sampler that is far from converged, you were able to produce posterior predictives that aligned well with the data and had good epistemic and aleatoric uncertainty. In fact, a number of works are showing that by capturing a little piece (if it is the right piece) of the true posterior of a BNN, you are able to capture most of the variation you want in the posterior predictive.\n",
    "\n",
    "In [\"Subspace Inference for Bayesian Deep Learning\"](https://arxiv.org/pdf/1907.07504.pdf), the authors provide toy examples where one obtains a posterior predictive distribution with good epistemic and aleatoric uncertainty by reducing a high dimensional parameter space to 2-dimensions and performing inference in the 2-dimensional subspace:\n",
    "<img src=\"fig/posterior_pred2.jpg\" style=\"height:210px;\" align=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# New Developments in Deep Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What's Wrong with Posterior Approximations for BNNs\n",
    "***(joint work with Jiayu Yao, Soumya Ghosh, Finale Doshi-Velez)***\n",
    "\n",
    "**The motivation:** Frequently, we introduce a new approximate inference method for BNNs based on our intuition of what properties of the true posterior are important to include in our approximate posterior. We then measure the ***log-likelihood*** of our learned model on test data.\n",
    "\n",
    "**The idea:** We evaluate the ability of a number of state-of-the-art approximate inference methods for BNN on synthetic data that can be visualized to see if various custom approximations of the posterior translates to desirable posterior predictives.\n",
    "\n",
    "We also test if the commonly used evaluation metrics, like test log-likelihood, can distinguish high quality posterior predictves from poor quality ones.\n",
    "\n",
    "***From:*** [Quality of Uncertainty Quantification for Bayesian Neural Network Inference](https://arxiv.org/pdf/1906.09686.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What Did We Learn?\n",
    "\n",
    "**Take-away:** Metric like test log-likelihood measures how well the approximate posterior predictive aligns with the data, not how well it approximate the true posterior predictive.\n",
    "\n",
    "<img src=\"fig/cubic_compare.png\" style=\"height:170px;\" align=\"center\"/>\n",
    "\n",
    "**Take-away:** Training with data gaps and evaluating test likelihood can only catch problems if the true function is complex in these gaps.\n",
    "\n",
    "<img src=\"fig/complex_compare.png\" style=\"height:110px;\" align=\"center\"/>\n",
    "\n",
    "**Take-away:** Inference methods that specialize in approximating specific properties in the posterior do not necessarily produce desirable posterior predictives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What's Wrong with the Predictions from Mean-Field Variational Posteriors of BNNs?\n",
    "***(joint work with Beau Coker, Finale Doshi-Velez)***\n",
    "\n",
    "The problem with mean-field VI for BNNs isn't just with the variance. In [Wide Mean-Field Variational Bayesian Neural Networks Ignore the Data](https://arxiv.org/pdf/2106.07052.pdf). we show that as the network width becomes wider, the posterior predictive mean ignores the data completely and learns a constant (flat) function!\n",
    "\n",
    "<img src=\"fig/widebnn.png\" style=\"height:300px;\" align=\"center\"/>\n",
    "\n",
    "The fact that the posterior predictive mean of mean-field variational posteriors of wide BNNs ***underfit*** the data has been observed empirically in [Overpruning in Variational Bayesian Neural Networks](https://arxiv.org/abs/1801.06230)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Relationships Between Deep Ensembles and Bayesian Neural Networks\n",
    "Althhough we've been thinking about ensembles and Bayesian models as belonging to a dichotomy (frequentist vs Bayesian statistics), in papers like [Conservative Uncertainty Estimation By Fitting Prior Networks](https://openreview.net/pdf?id=BJlahxHYDS) and [Repulsive Deep Ensembles are Bayesian](https://arxiv.org/abs/2106.11642), we see that ensembles and Bayesian models have a deep relationship.\n",
    "\n",
    "**Take-away:** In fact, some ensembles can be interpreted as collections of samples from a corresponding Bayesian model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Alternative Models for Uncertainty Quantification\n",
    "\n",
    "Although mean-field VI is touted as a fast way of performing inference on BNNs, they are still hard to scale to truly large networks. For this reason, alternative deep Bayesian models have been gaining popularity. **Neural Linear Models** is a model that learns deterministic weights for an NN except for the last layer, where we place priors and perform exact Bayesian inference:\n",
    "\n",
    "<img src=\"fig/Unknown-20.png\" style=\"height:280px;\" align=\"center\"/>\n",
    "\n",
    "***From:*** [Learned Uncertainty-Aware (LUNA) Bases for Bayesian Regression using Multi-Headed Auxiliary Networks](https://arxiv.org/pdf/2006.11695.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Predictive Uncertainties of Alternative Deep Bayesian Models May Not be Better\n",
    "***(joint work with Sujay Thakur, Cooper Lorsung, Yaniv Yacoby, Finale Doshi-Velez)***\n",
    "\n",
    "In [Learned Uncertainty-Aware (LUNA) Bases for Bayesian Regression using Multi-Headed Auxiliary Networks](https://arxiv.org/pdf/2006.11695.pdf), we show that the posterior predictive uncertainty of NLMs are not what we might want. The problem has a lot to do with how we typically train neural networks.\n",
    "\n",
    "<img src=\"fig/Unknown-18.png\" style=\"height:270px;\" align=\"center\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What Uncertainties Do We Need in Deep Learning?\n",
    "More and more folks in the Deep Bayes community is coming to the conclusion that the quality of uncertainty estimation can only be assessed in reference to a specific down-stream task, e.g. active learning, continual learning, Bayesian optimization, out of distribution detection, learning to defer (rejection learning), model interpretation etc.\n",
    "\n",
    "<img src=\"fig/bayesopt.png\" style=\"height:350px;\" align=\"center\"/>\n",
    "\n",
    "**Take-away:** There is no universal definition of or metric for \"good\" uncertainty - \"good\" uncertainty is uncertainty that is useful for the task.\n",
    "\n",
    "**Take-away:** Uncertainty estimation that is good for one task might be bad for another!"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
