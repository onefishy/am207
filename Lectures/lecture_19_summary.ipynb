{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture #19: Variational Inference in Context\n",
    "## AM 207: Advanced Scientific Computing\n",
    "### Stochastic Methods for Data Analysis, Inference and Optimization\n",
    "### Fall, 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"fig/logos.jpg\" style=\"height:150px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Lecture #19 Summary\n",
    "\n",
    "What did we observe in HW#8? We setup a BNN with 1 hidden layer and 5 hidden nodes.\n",
    "1. Did your HMC converge? Do you feel confident that you can get it to converge?\n",
    "    - Did the posterior samples give you desirable predictive uncertainty?<br><br>\n",
    "    \n",
    "2. Did your BBVI optimize the ELBO fully? How do you know that you've optimized your ELBO fully?\n",
    "    - Did the variational posterior give you desirable predictive uncertainty?<br><br>\n",
    "    \n",
    "3. When the network is large, do you believe that either HMC or mean-field Gaussian VI will give you a good approximation of the posterior?\n",
    "    - Do we necessarily need a good approximation of the posterior to get desirable uncertainty?<br><br>\n",
    "    \n",
    "4. **The Training Wheels are Off!** When doing machine learning in the wild, no one knows the \"right answer\", your metrics are not absolute, the only thing you can rely on is your intuition (which is you internalizing the theory you've learned as well as your hands-on experience working with these models).\n",
    "    - How can we know that our HMC has no bugs in it?\n",
    "    - How can we know that our BBVI has no bugs in it?\n",
    "    - How can we know that we've fully optimized anything (e.g. the ELBO) through gradient descent?\n",
    "    - What are the impediments to BBVI optimizing fully? I.e. what do we tune to improve performance?\n",
    "    - What are the impediments to HMC mixing? I.e. what do we tune to improve performance? <br><br>\n",
    "    \n",
    "5. **What this class is not:** This class is not a one-stop for all the tools you need to be a fluent practitioner of in-demand state-of-the art machine learning. It's normal that:\n",
    "    - You still don't feel like you're comfortable impplementing all the models from scratch and deploying it in real-life conditions. \n",
    "      You should **not** be comfortable now, but you will be with practice in the future (you're getting some of that practice with the project)!\n",
    "    - You don't remember everything from the class, and that as time passes, you seem to forget more.\n",
    "      You'll forget many if not most facts, but when you re-learn these facts, understanding will come more easily and with more depth.<br><br>\n",
    "\n",
    "6. **What is this class:** This class is a map or atlas and paints a broad landscape of modern-day probabilistic machine learning. Using the structure of this class you can better organize and process new ML knowledge. \n",
    "\n",
    "  This class is a foundation for you to build on, future classes in ML **will** reference these models, techniques and concepts:\n",
    "    - Reinforcement learning (Harvard)\n",
    "    - Causal inference (Harvard)\n",
    "    - ML for Healthcare (MIT)\n",
    "    - Neural Processing (Harvard)\n",
    "    - Special Topics in ML (Harvard)\n",
    "    - Interpretable ML (Harvard)\n",
    "    - AI for Social Good (Harvard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# New Developments in Deep Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What's Wrong with Posterior Approximations for BNNs\n",
    "***(joint work with Jiayu Yao, Soumya Ghosh, Finale Doshi-Velez)***\n",
    "\n",
    "**The motivation:** Frequently, we introduce a new approximate inference method for BNNs based on our intuition of what properties of the true posterior are important to include in our approximate posterior. We then measure the ***log-likelihood*** of our learned model on test data.\n",
    "\n",
    "**The idea:** We evaluate the ability of a number of state-of-the-art approximate inference methods for BNN on synthetic data that can be visualized to see if various custom approximations of the posterior translates to desirable posterior predictives.\n",
    "\n",
    "We also test if the commonly used evaluation metrics, like test log-likelihood, can distinguish high quality posterior predictves from poor quality ones.\n",
    "\n",
    "***From:*** [Quality of Uncertainty Quantification for Bayesian Neural Network Inference](https://arxiv.org/pdf/1906.09686.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What Did We Learn?\n",
    "\n",
    "**Take-away:** Metric like test log-likelihood measures how well the approximate posterior predictive aligns with the data, not how well it approximate the true posterior predictive.\n",
    "\n",
    "<img src=\"fig/cubic_compare.png\" style=\"height:170px;\" align=\"center\"/>\n",
    "\n",
    "**Take-away:** Training with data gaps and evaluating test likelihood can only catch problems if the true function is complex in these gaps.\n",
    "\n",
    "<img src=\"fig/complex_compare.png\" style=\"height:110px;\" align=\"center\"/>\n",
    "\n",
    "**Take-away:** Inference methods that specialize in approximating specific properties in the posterior do not necessarily produce desirable posterior predictives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What's Wrong with the Predictions from Mean-Field Variational Posteriors of BNNs?\n",
    "***(joint work with Beau Coker, Finale Doshi-Velez)***\n",
    "\n",
    "The problem with mean-field VI for BNNs isn't just with the variance. In [Wide Mean-Field Variational Bayesian Neural Networks Ignore the Data](https://arxiv.org/pdf/2106.07052.pdf). we show that as the network width becomes wider, the posterior predictive mean ignores the data completely and learns a constant (flat) function!\n",
    "\n",
    "<img src=\"fig/widebnn.png\" style=\"height:300px;\" align=\"center\"/>\n",
    "\n",
    "The fact that the posterior predictive mean of mean-field variational posteriors of wide BNNs ***underfit*** the data has been observed empirically in [Overpruning in Variational Bayesian Neural Networks](https://arxiv.org/abs/1801.06230)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Relationships Between Deep Ensembles and Bayesian Neural Networks\n",
    "Althhough we've been thinking about ensembles and Bayesian models as belonging to a dichotomy (frequentist vs Bayesian statistics), in papers like [Conservative Uncertainty Estimation By Fitting Prior Networks](https://openreview.net/pdf?id=BJlahxHYDS) and [Repulsive Deep Ensembles are Bayesian](https://arxiv.org/abs/2106.11642), we see that ensembles and Bayesian models have a deep relationship.\n",
    "\n",
    "**Take-away:** In fact, some ensembles can be interpreted as collections of samples from a corresponding Bayesian model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Alternative Models for Uncertainty Quantification\n",
    "\n",
    "Although mean-field VI is touted as a fast way of performing inference on BNNs, they are still hard to scale to truly large networks. For this reason, alternative deep Bayesian models have been gaining popularity. **Neural Linear Models** is a model that learns deterministic weights for an NN except for the last layer, where we place priors and perform exact Bayesian inference:\n",
    "\n",
    "<img src=\"fig/Unknown-20.png\" style=\"height:280px;\" align=\"center\"/>\n",
    "\n",
    "***From:*** [Learned Uncertainty-Aware (LUNA) Bases for Bayesian Regression using Multi-Headed Auxiliary Networks](https://arxiv.org/pdf/2006.11695.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Predictive Uncertainties of Alternative Deep Bayesian Models May Not be Better\n",
    "***(joint work with Sujay Thakur, Cooper Lorsung, Yaniv Yacoby, Finale Doshi-Velez)***\n",
    "\n",
    "In [Learned Uncertainty-Aware (LUNA) Bases for Bayesian Regression using Multi-Headed Auxiliary Networks](https://arxiv.org/pdf/2006.11695.pdf), we show that the posterior predictive uncertainty of NLMs are not what we might want. The problem has a lot to do with how we typically train neural networks.\n",
    "\n",
    "<img src=\"fig/Unknown-18.png\" style=\"height:270px;\" align=\"center\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What Uncertainties Do We Need in Deep Learning?\n",
    "More and more folks in the Deep Bayes community is coming to the conclusion that the quality of uncertainty estimation can only be assessed in reference to a specific down-stream task, e.g. active learning, continual learning, Bayesian optimization, out of distribution detection, learning to defer (rejection learning), model interpretation etc.\n",
    "\n",
    "<img src=\"fig/bayesopt.png\" style=\"height:350px;\" align=\"center\"/>\n",
    "\n",
    "**Take-away:** There is no universal definition of or metric for \"good\" uncertainty - \"good\" uncertainty is uncertainty that is useful for the task.\n",
    "\n",
    "**Take-away:** Uncertainty estimation that is good for one task might be bad for another!"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
