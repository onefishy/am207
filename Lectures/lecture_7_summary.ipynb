{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture #7: Markov Chain Monte Carlo\n",
    "## AM 207: Advanced Scientific Computing\n",
    "### Stochastic Methods for Data Analysis, Inference and Optimization\n",
    "### Fall, 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"fig/logos.jpg\" style=\"height:150px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary of Lecture #7\n",
    "\n",
    "1. **We need more samplers!** Now we've seen that every activity in Bayesian modeling requires sampling! But our current tool-box of sampler's isn't really that great.\n",
    "  - What's wrong with Inverse CDF Sampling?\n",
    "  - What's wrong with Rejection Sampling?\n",
    "  - What's wrong with Gibbs Sampling?<br><br>\n",
    "\n",
    "2. **Samplers as Markov Chains -- Markov Chain Monte Carlo Sampling:** Why do we need to talk about Markov Chains again?\n",
    "  - All the samplers we've seen so far define Markov Chains. *How?*\n",
    "  - What's the big deal with Markov Chains? They are easy to describe and analyze!\n",
    "    - Describing a Markov Chain just means describing how the chain evolves from a given state to the next (the ***transition matrix*** or ***transition kernel***)\n",
    "    - Many nice Markov Chains have predictable long-term (asymptotic) behavior, i.e. as time goes on, the probability that the chain will visit state $0$ is 0.6, the probability that the chain will visit state $1$ is 0.2 etc.\n",
    "  - What are some useful behaviors to look for in Markov Chains?\n",
    "    - Stationary distributions (i.e. when the market is 70% Apple customers and 30% Android then the market distribution will be stable)\n",
    "      - How do you check that a distribution $\\pi$ is stationary?\n",
    "    - Limiting distributions (i.e. however the market for smart phones start off, eventually it will be 70% Apple customers)\n",
    "      - How do you check that a distribution is limiting?\n",
    "    \n",
    "  - **Claim:** we want our samplers to have a limiting distribution and we want that distribution to be our target distribution!\n",
    "    - Why?\n",
    "    \n",
    "  - What kinds of Markov Chains have limiting distributions?\n",
    "    \n",
    "    **Fundamental Theorem of Markov Chains:** if a Markov chain is ***irreducible*** and ***aperiodic***, then it has a *unique* stationary distribution $\\pi$ and $\\pi^{\\infty} = \\underset{n\\to \\infty}{\\lim}\\pi^{(n)} = \\pi$.\n",
    "\n",
    "    In practice, the theorem says you can start with any initial distribution over the state space $\\mathcal{S}$, asymptotically, you will always obtain the distribution $\\pi$.\n",
    "\n",
    "    While we unfortunately can't prove the theorem, we can indicate why both conditions are helpful.\n",
    "\n",
    "    <img src=\"fig/counter.jpg\" style=\"height:250px;\">\n",
    "    \n",
    "  - But how do I check that the limiting distribution is our target distribution?\n",
    "    - We check that our sampler satisfy the ***detailed balance*** condition with respect to the target distribution.\n",
    "    - **Theorem:** If a Markov chain satisfies the ***detailed balance*** condition with respect to $\\pi$. Then $\\pi$ is a stationary distribution of the chain.\n",
    "    - By the Fundamental Theorem, an irreducible and aperiodic Markov Chain, since our target distribution is stationary, it must be the limiting distribution.<br><br>\n",
    "    \n",
    "    \n",
    "3. **How Do I Use This In Practice?** What do we need to prove to show that our sampler is correct (is an MCMC sampler)?\n",
    "  - Show that the Markov Chain defined by our sampler is irreducible and aperiodic\n",
    "  - Show that the sampler satisfies detailed balance with respect to the target distribution \n",
    "  - Invoke the Fundamental Theorem<br><br>\n",
    "\n",
    "4. **But do I HAVE to be Bayesian???** So some of you might be thinking, I will never work with a Bayesian model because MLE's are so easy to compute. You'll be disappointed to find out in Lecture #9 that MLE inference be just as difficult as Bayesian inference.<br><br>\n",
    "\n",
    "5. **But do I HAVE to do probabilistic machine learning at all???** Related questions:\n",
    "  - If not you who?\n",
    "  - What is the broader impact of MCMC theory?<br><br>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
