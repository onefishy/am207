{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture #6: Monte Carlo Integration\n",
    "## AM 207: Advanced Scientific Computing\n",
    "### Stochastic Methods for Data Analysis, Inference and Optimization\n",
    "### Fall, 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"fig/logos.jpg\" style=\"height:150px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Lecture #6 Summary\n",
    "\n",
    "1. **Why Are We Sampling Again?** AKA Bayesian Model Evaluation\n",
    "  - ***(Posterior Predictive Check: Obviously Needs Sampling)*** Use the models in the posterior to generate synethic data, in order to compare with real data, i.e. sample from the posterior predictive. \n",
    "  - ***(Marginal Data Log-Likelihood: Secretely Needs Sampling)*** Compute the marginal log-likelihood of the data (train or test) over the posterior: \n",
    "    \\begin{align}\n",
    "    \\sum_{m=1}^M \\log \\int_\\Theta p(\\mathbf{y}^*_m | \\theta) p(\\theta| \\text{Data}) d\\theta\n",
    "    \\end{align}<br><br>\n",
    "    \n",
    "2. **Integration Requires Sampling!** Monte Carlo Integration\n",
    "  - **Recognize your integral as an expectation:** $$\\int_\\Theta \\underbrace{p(\\mathbf{y}^*_m | \\theta)}_{\\text{$f(\\theta)$}}\\underbrace{p(\\theta| \\text{Data})}_{\\text{pdf of $\\theta$}} d\\theta = \\mathbb{E}_{\\theta\\sim p(\\theta|\\text{Data})}\\left[ p(\\mathbf{y}^*_m | \\theta)\\right]$$\n",
    "  - **Approximate the expectation (theoretical mean) with sampling mean:** $$\\underbrace{\\mathbb{E}_{\\theta\\sim p(\\theta|\\text{Data})}\\left[ p(\\mathbf{y}^*_m | \\theta)\\right]}_{I} \\approx \\underbrace{\\frac{1}{S}\\sum_{s=1}^S p(\\mathbf{y}^*_m | \\theta_s),\\, \\theta_s \\sim p(\\theta | Y)}_{\\widehat{I}}$$\n",
    "    Why is this valid again? That is, what are the desirable properties of the estimator $\\widehat{I}$?\n",
    "    \n",
    "  - **Reduce the variance of estimator $\\widehat{I}$:** What are the two factors contributing to the variance of $\\widehat{I}$?\n",
    "    - *Control Variates:* \n",
    "      - Need to choose $h(\\theta)$ such that ...?\n",
    "      - Need to choose constant $c$\n",
    "      - Then $\n",
    "\\widehat{I}_{\\text{control}} = \\frac{1}{S}\\sum^S_{s=1} f(\\theta_s) - c(h(\\theta_s) - \\mu_h)\n",
    "$\n",
    "      - How do I get the greatest variance reduction? Why is it hard to achieve? <br><br>\n",
    "      \n",
    "    - *Stratified Sampling:* \n",
    "      - Need to choose the strata, e.g. a way to break up the domain of $\\theta$, such that ...?\n",
    "      - Need to renormalize $p$ so it's a pdf over each stratum\n",
    "      $$\n",
    "\\frac{p(\\theta)}{w_m},\\quad w_m = \\int_{\\Theta_m} p(\\theta)d\\theta.\n",
    "$$\n",
    "      - Estimate the integral $\\mathbb{E}_{\\theta \\sim \\frac{p(\\theta)}{w_m}\\mathbb{1}_{\\Theta_m}}[f(\\theta)]$ on each stratum  estimated with $S_m = w_m * S$ samples\n",
    "      - Piece together the integral over the entire domain of $\\theta$\n",
    "      $$\n",
    "\\widehat{I}_{\\text{SS}} = \\sum_{m=1}^M w_m \\widehat{I}_m.\n",
    "$$\n",
    "\n",
    "    - *Importance Sampling:*\n",
    "      - Need to choose importance distribution $q(\\theta)$ such that ...?\n",
    "      - Sample from your importance distribution and then, instead of trashing samples unlikely under $p$, we down-weight their importance in the Monte Carlo sum\n",
    "      $$\\widehat{I}_{\\text{IS}} = \\frac{1}{S}\\sum_{s=1}^S \\underbrace{\\frac{p(\\theta_s|Y)}{q(\\theta_s)}}_{\\text{Importance Weight}}f(\\theta_s), \\; \\theta_s \\sim q(\\theta_s)$$\n",
    "      - Why do we need importance sampling? Why is it hard to achieve variance reduction with importance sampling?"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
