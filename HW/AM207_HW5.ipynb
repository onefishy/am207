{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework #5 (Due 10/14/2021, 11:59pm)\n",
    "## Hierarchical Models and the Theory of Variational Inference\n",
    "\n",
    "**AM 207: Advanced Scientific Computing**<br>\n",
    "**Instructor: Weiwei Pan**<br>\n",
    "**Fall 2021**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Name:**\n",
    "\n",
    "**Students collaborators:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions:\n",
    "\n",
    "**Submission Format:** Use this notebook as a template to complete your homework. Please intersperse text blocks (using Markdown cells) amongst `python` code and results -- format your submission for maximum readability. Your assignments will be graded for correctness as well as clarity of exposition and presentation -- a “right” answer by itself without an explanation or is presented with a difficult to follow format will receive no credit.\n",
    "\n",
    "**Code Check:** Before submitting, you must do a \"Restart and Run All\" under \"Kernel\" in the Jupyter or colab menu. Portions of your submission that contains syntactic or run-time errors will not be graded.\n",
    "\n",
    "**Libraries and packages:** Unless a problems specifically asks you to implement from scratch, you are welcomed to use any `python` library package in the standard Anaconda distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import basic libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_df is the dataframe of your data\n",
    "# estimates_df is a numpy array of cancer rate estimates, one for each county\n",
    "def scatter_plot_cancer_rates(data_df, estimates=None):\n",
    "    ax = data_df.plot(kind='scatter', x=\"pop\",y=\"pct_mortality\", alpha=0.0001, color=\"grey\")\n",
    "    bot_kcancer_counties = data_df.sort_values(by='pct_mortality',ascending=True)[:300]\n",
    "    top_kcancer_counties = data_df.sort_values(by='pct_mortality',ascending=False)[:300]\n",
    "    top_kcancer_counties.plot(kind='scatter',x=\"pop\",y=\"pct_mortality\",alpha=0.0001, color=\"blue\", ax=ax, logx=True)\n",
    "    bot_kcancer_counties.plot(kind='scatter',x=\"pop\",y=\"pct_mortality\",alpha=0.0001, color=\"red\", ax=ax, logx=True)\n",
    "    if estimates is not None:\n",
    "        ax.plot(data_df['pop'], 5 * estimates, '.', alpha=0.2, color=\"green\")\n",
    "    ax.set_ylim([-0.0001, 0.0003])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Description: Understanding EM and Variational Inference\n",
    "\n",
    "In this problem, we will draw concrete connections between EM and variational inference by applying both methods to a certain class of latent variable models. You'll need to refer to relevant lecture notes on the derivations of EM and the derivation of the variational inference objective. This is an essay question that requires you to engage with complex derivations at a productive but still high level. No implementation is required.\n",
    "\n",
    "#### Non-Bayesian Latent Variable Model\n",
    "Recall the class of latent variable models we studied in lecture:\n",
    "<img src=\"fig/graphical_model.jpg\" style=\"height:150px;\">\n",
    "\n",
    "#### Bayesian Latent Variable Model\n",
    "A Bayesian version of the same class of models involve adding priors for the model parameters:\n",
    "<img src=\"fig/bayesian_model.jpg\" style=\"height:150px;\">\n",
    "\n",
    "1. **(Comparing ELBOs)** For the above type of Bayesian latent variable model, write down the ELBO for variational inference with a mean field variational family. Compare the variational inference ELBO for the Bayesian model to the expectation maximization ELBO for the non-Bayesian model. What are the differences and similarities between these two ELBOs?\n",
    "\n",
    "  In both EM and variational inference we optimize the ELBO. Compare the update steps in EM to the update steps in Coordinate Ascent Variational Inference, draw a concrete analogy between them.\n",
    "  \n",
    "  ***Hint:*** To make both ELBO's comparable, make sure that both are in terms of $z, y, \\theta, \\phi$.\n",
    "  <br><br>\n",
    "  \n",
    "2. **(Comparing ELBOs and KL-divergences)** Recall that the original objective of variational inference is to minimize a KL-divergence, we rewrote the objective to be that of maximizing the ELBO. Why is directly minimizing the KL-divergence in the original objective difficult (be specific about wherein the difficulty lies)? \n",
    "\n",
    "  In the derivation of the E-step of EM, we reframed an maximization of the ELBO problem as a minimization of a KL-divergence problem. In this case, why was the KL-divergence easier to minimize and the ELBO harder to maximize (use the instantiation of the E-step for Gaussian Mixture Models in Lecture 7 to help support your answer)? \n",
    "\n",
    "  In the notes for Lecture 8, we introduce a way to maximize the variational inference ELBO -- through coordinate ascent. In the derivation of the updates for coordinate ascent, there is a place where we reframed an maximization of the ELBO problem as an equivalent minimization of a KL-divergence problem. Write down the exact form of this equivalence (the two expressions are separated in the derivation by a bunch of lines, you'll need to identify both parts that you need). In this case, why was the KL-divergence easier to minimize and the ELBO harder to maximization (use the instantiation of the update for Gaussian Mixture Models in Lecture 8 to help support your answer)?\n",
    "\n",
    "  Based on this analysis, can you draw some general conclusions about when we'd prefer to minimize the KL-divergence versus when we'd prefer to maximize the ELBO?<br><br>\n",
    "\n",
    "3. **(The Mean Field Assumption and Coordinate Ascent)**  Describe exactly when and how the mean field assumption is used in the derivation of the coordinate ascent updates. <br><br>\n",
    "\n",
    "4. **(Generalizability of CAVI)** Summarize what kind of derivations/math is needed in order instantiate Coordinate Ascent Variational Inference (CAVI) for a given new model (look at what we did for Gaussian Mixture Models in Lecture 8 and predict what you'd need to do for a new model). Based on this, discuss the potential draw backs of using CAVI for Bayesian inference in general. What do these draw backs imply about the practicality of variational inference as an inference method?<br><br>\n",
    "\n",
    "5. **(Generalizability of EM)** Summarize what kind of derivations/math is needed in order instantiate Expectation Maximization (EM) for a given new model (look at what we did for Gaussian Mixture Models in Lecture 9 and predict what you'd need to do for a new model). Based on this, discuss the potential draw backs of using EM for MLE inference in general. What do these draw backs imply about the practicality of EM as an inference method?\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Description: Modeling Kidney Cancer Data\n",
    "In this problem, we will continue to work with the US Kidney Cancer Data set, `kcancer.csv`. This is a dataset of kidney cancer frequencies across the US over 5 years on a per county basis. \n",
    "\n",
    "**In this homework, we focus on comparing different types of models for this data set.**\n",
    "\n",
    "\n",
    "## Part I: Empirical Bayes\n",
    "Let $N$ be the number of counties; let $y_j$ the number of kidney cancer case for the $j$-th county, $n_j$ the population of the $j$-county and $\\theta_j$ be the underlying kidney cancer rate for that county. The following is a Bayesian model for our data:\n",
    "\n",
    "\\begin{aligned}\n",
    "y_j | \\theta_j &\\sim Poisson(5 \\cdot n_j \\cdot \\theta_j), \\quad j = 1, \\ldots, N\\\\\n",
    "\\theta_j &\\sim Gamma(\\alpha, \\beta), \\quad j = 1, \\ldots, N\n",
    "\\end{aligned}\n",
    "\n",
    "where $\\alpha, \\beta$ are hyper-parameters of the model.\n",
    "\n",
    "1. **(Visualize the raw cancer rates)** Produce a scatter plot of the raw cancer rates (pct mortality) vs the county population size (in log scale). Highlight the top 300 raw cancer rates in red. Highlight the bottom 300 raw cancer rates in blue. What can you say about the counties with the highest and lowest raw cancer rates.<br><br>\n",
    "\n",
    "2. **(Empirical Bayes)** Using Empirical Bayes and moment matching, choose values for the hyperparameters $\\alpha, \\beta$ based on your data. Use these values of $\\alpha$ and $\\beta$ to obtain posterior distributions for each county.\n",
    "\n",
    "***Hint:*** You'll first need to derive the fact that the ***evidence*** for a Poisson-Gamma model has a Negative Binomial distribution.<br><br>\n",
    "\n",
    "3. **(Posterior Means)** Produce a scatter plot of the raw cancer rates (pct mortality) vs the county population size (in log scale). Highlight the top 300 raw cancer rates in red. Highlight the bottom 300 raw cancer rates in blue. Finally, on the same plot again, scatter plot the posterior mean cancer rate estimates vs the county population size, highlight these means in green. \n",
    "\n",
    "  Using the scatter plot, explain why using the posterior means (from our model) to estimate cancer rates is preferable to studying the raw rates themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II: Hierarchical Bayes\n",
    "Rather than choosing fixed constants for the hyperparameters $\\alpha, \\beta$, following the Bayesian philosophy, we typically put additional priors on quantities of which we are uncertain. That is, we model the kidney cancer rates using a ***hierarchical model***:\n",
    "\n",
    "\\begin{aligned}\n",
    "y_j| \\theta_j &\\sim Poisson(5 \\cdot n_j \\cdot \\theta_j), \\quad j = 1, \\ldots, N\\\\\n",
    "\\theta_j | \\alpha, \\beta &\\sim Ga(\\alpha, \\beta), \\quad j = 1, \\ldots, N\\\\\n",
    "\\alpha &\\sim Ga(a, b)\\\\\n",
    "\\beta &\\sim Ga(c, d)\n",
    "\\end{aligned}\n",
    "where $a, b, c, d$ are hyperparameters. \n",
    "\n",
    "1.  **(Posterior Marginal Means)** Produce a scatter plot of the raw cancer rates (pct mortality) vs the county population size (in log scale). Highlight the top 300 raw cancer rates in red. Highlight the bottom 300 raw cancer rates in blue. Finally, on the same plot again, scatter plot the mean of the posterior marginal distribution over $\\theta_j$, i.e. $p(\\theta_j|y_1, \\ldots, y_N)$, vs the county population size (in log scale), highlight these means in orange. \n",
    "\n",
    "  You should use `pymc3` to sample from the posterior. Compare `pymc3`'s sampler with your sampler from the previous homework, what is the difference (if any) in the performance of these samplers?<br><br>\n",
    "\n",
    "2.  **(Hierarchical Bayes vs Empirical Bayes)** Compare the shrinkage of the posterior marginal means of the hierarchical model to the shrinkage of the posterior means from the Bayesian model with empirical Bayes estimates for $\\alpha, \\beta$. What is the difference in shrinkage between the full hierarchical model and the Bayesian model with empirical Bayes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part III: Broader Impact Analysis\n",
    "\n",
    "Starting in 2020, major machine learning conferences are beginning to ask authors as well as reviewers to explicitly consider the broader impact of new machine learning methods. To properly evaluate the potential good or harm that a piece of technology (AI or not) can do to the general public, we need to be aware that no technology is deployed in ideal conditions or in perfectly neutral contexts. In order to assess the potential broader impact of technology, we need to analyze the social systems/institutions of which these technologies will become a part.\n",
    "\n",
    "To help you analyze the broader impact of your technology, begin by considering the following questions:\n",
    "\n",
    "I. Identify the relevant socio-technical systems\n",
    "  - In what social, political, economic system could the tech be deployed?\n",
    "  - How would the tech be used in these systems (what role will it take in the decision making processes)?<br><br>\n",
    "  \n",
    "II. Identify the stakeholders\n",
    "  - Who are the users?\n",
    "  - Who are the affected communities (are these the users)?\n",
    "  \n",
    "    ***Hint:*** users are typically decision makers who will use the technology as decision aids (e.g. doctors), whereas affected communities may be folks who are impacted by these decisions but who are not represented in the decision making process (e.g. patients).<br><br>\n",
    "    \n",
    "III. What types of harm can this tech do?\n",
    "  - What kinds of failures can this tech have?\n",
    "  - What kinds of direct harm can these failures cause?\n",
    "  - What kinds of harm can the socio-technical system cause?\n",
    "  \n",
    "    ***Hint:*** many technical innovations have niche applications, they may sit in a long chain of decision making in a complex system. As such, it may seem, at first glance, that these technologies have no immediate real-life impact. In these cases, it’s helpful to think about the impact of the entire system and then think about how the proposed innovations aid, hamper or change the goals or outcomes of this system.<br><br>\n",
    "    \n",
    "IV. What types of good can this tech do?\n",
    "  - What kinds of needs do these users/communities have?\n",
    "  - What kinds of constraints do these users/communities have?<br><br>\n",
    "  \n",
    "1. **(Computational Footprint)**  In Homework #4, we considered the broader impact of the this hierarchical model for kidney cancer: we examined under what circumstances a hierachical model for kidney cancer is more preferable to a MLE model or a Bayesian model with hand-picked priors. In this problem, we compare hierarchical Bayes and empirical Bayes. \n",
    "\n",
    "  In practical terms, what are the real-life advantages and drawbacks of implementing an empirical Bayesian model compared with an hierarchical Bayesian model?\n",
    "  \n",
    "  **Hint:** for example, compare how tractable it is to implement the inference algorithm for each model, compare how easy it is to for the inference method for each model to converge (would you know that your training has converged?). Consider also: how easily could a practitioner diagnose the training process and how could they evaluate the model fit and what kinds of computational resurces would be required to train each model.\n",
    "  \n",
    "2. **(Mitigation of Potential Negative Impacts)** Based on your answers for the previous question and your broader impact analysis from HW#4, what information would the model designer/engineer need to disclose to the end-users to mitigate potentially negative impacts?\n",
    "\n",
    "  **Hint:** consider how your end-user would be able to validate the model (how would they know if the model is working or has ceased to work once it has been deployed), how should the end-user choose between implementing a hiearchical Bayesian model or an empirical Bayesian model, how could the end-user identify and mitigate negative impacts (if they occur).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
