{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework #0 (Due 09/09/2021, 11:59pm)\n",
    "## Review of Stastistical Modeling and Scientific Computing\n",
    "\n",
    "**AM 207: Advanced Scientific Computing**<br>\n",
    "**Instructor: Weiwei Pan**<br>\n",
    "**Fall 2021**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Name:**\n",
    "\n",
    "**Students collaborators:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions:\n",
    "\n",
    "**Submission Format:** Use this notebook as a template to complete your homework. Please intersperse text blocks (using Markdown cells) amongst `python` code and results -- format your submission for maximum readability. Your assignments will be graded for correctness as well as clarity of exposition and presentation -- a “right” answer by itself without an explanation or is presented with a difficult to follow format will receive no credit.\n",
    "\n",
    "**Code Check:** Before submitting, you must do a \"Restart and Run All\" under \"Kernel\" in the Jupyter or colab menu. ***Portions of your submission that contains syntactic or run-time errors will not be graded***.\n",
    "\n",
    "**Libraries and packages:** Unless a problems specifically asks you to implement from scratch, you are welcomed to use any `python` library package in the standard Anaconda distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import basic libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I: Maximum Likelihood Estimators for Linear Regression\n",
    "### (Material covered in CS109A or equivalent)\n",
    "In this problem, you are given a dataset with a single predictor $X$ representing patient age (in years) and a single outcome $y$ representing diastolic blood pressure (in mm Hg), and your task is to fit a linear model to the data. The fitted model will be deployed in a hospital setting, where the model predictions will inform patient treatment. \n",
    "\n",
    "The dataset is saved as `HW0_data.csv` in CSV (Comma Separated Values) format and can be read using the `.read_csv()` function from the `pandas` library.\n",
    "\n",
    "Assume that the outcome $y$ can be modeled by the following process:\n",
    "\\begin{aligned}\n",
    "y &= f(x) + \\epsilon = w_1x + w_0 + \\epsilon, \\quad \\epsilon \\sim \\mathcal{N}(0, 0.5)\n",
    "\\end{aligned}\n",
    "where $w_1$ and $w_0$, the *parameters* of the function $f$, are unknown constants. \n",
    "\n",
    "1. **(Model Building)** Write the analytical expression for the likelihood function $p(y|x, w_1, w_0)$, for a single observation $(x, y)$. Write the analytical expression for the likelihood function $\\prod_{n=1}^N p(y_n|x_n, w_1, w_0)$ for an entire dataset of $N$ number of observations. \n",
    "\n",
    "  *Hint: for a given $x$ and fixed parameters, what is the distribution of $y$?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **(Defining a Learning Objective)** The Maximum Likelihood Estimators (MLE) of $w_1$ and $w_0$ are defined as\n",
    "\\begin{aligned}\n",
    "w^{\\text{MLE}}_1, w^{\\text{MLE}}_0 = \\underset{w_1, w_0}{\\mathrm{argmax}}\\; \\prod_{n=1}^N p(y_n|x_n, w_1, w_0)\n",
    "\\end{aligned}\n",
    "Show that finding $w_1$ and $w_0$ that maximizes the likelihood is equivalent to finding parameters that minimize the Mean Squared Error (MSE) of your model.<br><br>\n",
    "*Hint: show that maximizing the log likelihood is equivalent to minimizing the MSE.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **(Model Fitting)** Analytically derive the formulae for MLE of $w_1$ and $w_0$. Describe what information you would need in order ***prove*** that the parameters you derived maximizes the likelihood (or minimizes the MSE)?\n",
    "\n",
    "  **Optional but Useful:** express your derivation of the MLE in matrix notation (i.e. [perform matrix calculus](https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf)).\n",
    "\n",
    "  *Hint: this part requires multivariate calculus.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **(Model Evaluation)** Using the `LinearRegression` class from `sklearn.linear_model`, fit a linear regression model to the dataset in `HW0_data.csv`. When you call the `.fit()` function of `LinearRegression`, the default is to find parameters that minimize MSE.\n",
    "\n",
    "  Visualize the linear function you fitted as well as the data in one plot. \n",
    "  Visualize a histogram of the residuals.\n",
    "  \n",
    "  Interpret the clinical meaning of the parameters $w_0, w_1$.\n",
    "  \n",
    "  Using the plots and your interpretation of the model parameters, argue for whether or not your model is appropriate for the data.\n",
    "  \n",
    "  *Hint: look at the assumptions you've made in your modeling process, which assumptions are supported by the data, which are contradicted by the data?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part II: Bayesian Linear Regression\n",
    "### (Material covered in CS109 B or equivalent)\n",
    "In this problem, your task is to perform Bayesian linear regression on the dataset in `HW0_data.csv`.\n",
    "\n",
    "Assume that the outcome $y$ can be modeled by the following process:\n",
    "\\begin{aligned}\n",
    "y &= f(x) + \\epsilon = w_1x + w_0 + \\epsilon, \\quad \\epsilon \\sim \\mathcal{N}(0, 0.5)\\\\\n",
    "w_0 &\\sim \\mathcal{N}(0, 1)\\\\\n",
    "w_1 &\\sim \\mathcal{N}(0, 0.5)\n",
    "\\end{aligned}\n",
    "In this model, we assume the same likelihood as in Part I, but we also include priors for $w_0$ and $w_1$: $p(w_0) = \\mathcal{N}(0, 1)$, $p(w_1) = \\mathcal{N}(0, 0.5)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **(Inference)** Analytically derive the joint posterior distribution over the parameters. That is, analytically compute<br><br>\n",
    "\\begin{aligned}\n",
    "p(w_1, w_0 | y_1, \\ldots y_n, x_1, \\ldots, x_n) = \\frac{\\left(\\prod_{n=1}^Np(y_n|x_n, w_1, w_0)\\right)p(w_1)p(w_0)}{\\prod_{n=1}^Np(y_n|x_n)}.\\\\\n",
    "\\end{aligned}\n",
    "<br>*Hint: The posterior of a model with a Gaussian (or normal) likelihood and Gaussian priors is yet again Gaussian. This derivation is included in many machine learning textbooks like Machine Learning: a Probabilistic Perspective by Murphy or Pattern Recognition and Machine Learning by Bishop. This derivation also appears online in many course notes - you are welcomed to use any and all available resources.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **(Model Interpretation)** Visualize the ***joint posterior*** over the parameters, $p(w_1, w_0 | y, x)$ for the dataset in `HW0_data.csv` (you may use a scatter plot of samples drawn from the posterior or a contour map/heat map of the pdf). In separate plots, visualize the ***marginal posterior*** distribution over each parameter,\n",
    "\\begin{aligned}\n",
    "p(w_1 | y_1, \\ldots y_n, x_1, \\ldots, x_n) &= \\int_{w_0} p(w_1, w_0 | y_1, \\ldots y_n, x_1, \\ldots, x_n) dw_0\\\\\n",
    "p(w_0 | y_1, \\ldots y_n, x_1, \\ldots, x_n) &= \\int_{w_0} p(w_1, w_0 | y_1, \\ldots y_n, x_1, \\ldots, x_n) dw_1\\\\\n",
    "\\end{aligned}\n",
    "Is the information contained in the joint posterior $p(w_1, w_0 | y_1, \\ldots y_n, x_1, \\ldots, x_n)$ equivalent to the information contained in the two marginals $p(w_1 | y_1, \\ldots y_n, x_1, \\ldots, x_n), p(w_0 | y_1, \\ldots y_n, x_1, \\ldots, x_n)$? That is, what does each distribution tell you?\n",
    "\n",
    "  Compute the variance of the marginal posterior distributions $p(w_i | y_1, \\ldots y_n, x_1, \\ldots, x_n)$ empirically using samples from $p(w_i | y_1, \\ldots y_n, x_1, \\ldots, x_n)$. What do the width of these intervals tell you about your confidence in the model's estimation of the parameters?\n",
    "\n",
    "   *Hint: it is not necessary to analytically derive the marginals $p(w_i | y_1, \\ldots y_n, x_1, \\ldots, x_n)$. Recall that you can perform marginalization of a variable by sampling from the joint distribution and disregarding that variable.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **(Prediction)** In Bayesian linear regression, we obtain a distribution over possible parameters given the data, $p(w_1, w_0 | y_1, \\ldots y_n, x_1, \\ldots, x_n)$, rather than a single ***point-estimate*** of the 'best' parameters. This means that when we predict an outcome for, say, $x=2$ we get a distribution over possible values of $y$ rather than a single $y$. The distribution over the predicted $y$ for a given $x$ is called the ***posterior predictive***, and is denoted $p(y|x)$.\n",
    "\n",
    "  Visualize the **95% posterior predictive interval** (this is the interval that includes 95% of the posterior predictive values) for the training data -- this is usually visualized as a shaded tube containing the 95% of the posterior predictive values for each test $x$-value. \n",
    "  \n",
    "  What does the 95% posterior predictive interval tell you about the model's uncertainty in its predictions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part III: Broader Impact Analysis\n",
    "\n",
    "You've now modeled the same set of data using non-Bayesian and Bayesian regression models. In both paradigms it's possible to identify a 'best' set of model parameters (in the non-Bayesian approach, we compute the MLE; in the Bayesian approach, we can compute the mean or mode of the posterior). For the Bayesian model, we also quantified our uncertainty in the model parameters as well as our uncertainty in the model's predictions. So which model, if any, should we deploy in real life?\n",
    "\n",
    "Starting in 2020, major machine learning conferences are beginning to ask authors as well as reviewers to explicitly consider the broader impact of new machine learning methods. To properly evaluate the potential good or harm that a piece of technology (AI or not) can do to the general public, we need to be aware that no technology is deployed in ideal conditions or in perfectly neutral contexts. In order to assess the potential broader impact of technology, we need to analyze the social systems/institutions of which these technologies will become a part.\n",
    "\n",
    "To help you analyze the broader impact of your technology, begin by considering the following questions:\n",
    "\n",
    "I. Identify the relevant socio-technical systems\n",
    "  - In what social, political, economic system could the tech be deployed?\n",
    "  - How would the tech be used in these systems (what role will it take in the decision making processes)?<br><br>\n",
    "  \n",
    "II. Identify the stakeholders\n",
    "  - Who are the users?\n",
    "  - Who are the affected communities (are these the users)?\n",
    "  \n",
    "    ***Hint:*** users are typically decision makers who will use the technology as decision aids (e.g. doctors), whereas affected communities may be folks who are impacted by these decisions but who are not represented in the decision making process (e.g. patients).<br><br>\n",
    "    \n",
    "III. What types of harm can this tech do?\n",
    "  - What kinds of failures can this tech have?\n",
    "  - What kinds of direct harm can these failures cause?\n",
    "  - What kinds of harm can the socio-technical system cause?\n",
    "  \n",
    "    ***Hint:*** many technical innovations have niche applications, they may sit in a long chain of decision making in a complex system. As such, it may seem, at first glance, that these technologies have no immediate real-life impact. In these cases, it’s helpful to think about the impact of the entire system and then think about how the proposed innovations aid, hamper or change the goals or outcomes of this system.<br><br>\n",
    "    \n",
    "IV. What types of good can this tech do?\n",
    "  - What kinds of needs do these users/communities have?\n",
    "  - What kinds of constraints do these users/communities have?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **(Impact)** Analyze the broader impact of these two models. Specifically, focus on anticipating ways these models can interact with other components of the decision systems in which they will be deployed, identifying end-users, affected communities as well as anticipating the effects (positive and negative) on affected communities (in particular, does the model have the same effect on all subpopulations in the affected communities?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **(Mitigation)** Which model, if any, would you recommend to deploy? Why? \n",
    "\n",
    "  What information should the ML designer/engineer disclose to the end-users to mitigate potential negative impacts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
